{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "282be102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 4898\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 84.2697\n"
     ]
    }
   ],
   "source": [
    "# FoML Assign 1 Code Skeleton\n",
    "# Please use this outline to implement your decision tree. You can add any code around this.\n",
    "import csv\n",
    "import math\n",
    "from __future__ import print_function\n",
    "\n",
    "# Enter Your Name Here\n",
    "myname = \"Rohan B M\" \n",
    "Roll_No = \"BM21MTECH14003\"\n",
    "\n",
    "#Q3.a - Decision tree Implementation (Using Entropy and information gain)\n",
    "class DecisionTree():\n",
    "    tree = {}\n",
    "    def learn(self, training_set):\n",
    "        training_data=[]\n",
    "        for y in training_set:\n",
    "            row=[]\n",
    "            for x in y: \n",
    "                row.append(float(x))\n",
    "            training_data.append(row)\n",
    "\n",
    "        print(\"Decision tree implementing...\")\n",
    "        print(\"Working on decisionTree, please wait for execution...\")\n",
    "        my_tree = build_tree(training_data)\n",
    "        self.tree[\"decision_tree\"]=my_tree\n",
    "       \n",
    "\n",
    "    def classify(self, test_instance):\n",
    "        row=[]\n",
    "        for x in test_instance:\n",
    "            row.append(float(x))\n",
    "        row.append(17)\n",
    "        result = list(classify(row, self.tree[\"decision_tree\"]).keys())[0]\n",
    "        return result\n",
    "\n",
    "\n",
    "#Find entropy \n",
    "def entropy(rows):\n",
    "    count = class_count(rows)\n",
    "    entropy = 0\n",
    "    for lbl in count:\n",
    "        prob_lbl = count[lbl] / float(len(rows))\n",
    "        entropy += prob_lbl*find_log(prob_lbl)\n",
    "    return -1*entropy\n",
    "\n",
    "#Find information gain\n",
    "def information_gain(left, right, present_impurity):\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return present_impurity - p * entropy(left) - (1 - p) * entropy(right)\n",
    "\n",
    "def class_count(rows):\n",
    "    count = {}  \n",
    "    for row in rows:\n",
    "        \n",
    "        label = row[-1]\n",
    "        if label not in count:\n",
    "            count[label] = 0\n",
    "        count[label] += 1\n",
    "    return count\n",
    "\n",
    "def find_best_split(rows):\n",
    "    best_gain = 0  \n",
    "    best_question = None  \n",
    "    present_impurity = entropy(rows)\n",
    "    n_features = len(rows[0]) - 1  \n",
    "\n",
    "    for cols in range(n_features):  \n",
    "        values = set([row[cols] for row in rows])  \n",
    "\n",
    "        for val in values:  \n",
    "            question = Question(cols, val)\n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "            \n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            gain = information_gain(true_rows, false_rows, present_impurity)\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "\n",
    "    return best_gain, best_question\n",
    "\n",
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "def unique_values(rows, cols):\n",
    "    return set([row[cols] for row in rows])\n",
    "\n",
    "def find_log(m):\n",
    "    n = math.log(m, 2)\n",
    "    return n\n",
    "def partition(rows, question):\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows\n",
    "\n",
    "def build_tree(rows):\n",
    "    gain, question = find_best_split(rows)\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "    true_branch = build_tree(true_rows)\n",
    "    false_branch = build_tree(false_rows)\n",
    "    return Decision_Node(question, true_branch, false_branch)\n",
    "\n",
    "\n",
    "def print_tree(node, spacing=\"\"):    \n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + \"Predict\", node.predictions)\n",
    "        return\n",
    "    print(spacing + str(node.question))\n",
    "\n",
    "    print(spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    print(spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")\n",
    "\n",
    "class Leaf:  \n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_count(rows)\n",
    "\n",
    "\n",
    "def classify(row, node):\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "    \n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)\n",
    "\n",
    "\n",
    "class Question:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "    def match(self, example):  \n",
    "        val = example[self.column]\n",
    "        if is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "\n",
    "    def __repr__(self):  \n",
    "        condition = \"==\"\n",
    "        if is_numeric(self.value):\n",
    "            condition = \">=\"\n",
    "        return \"Is %s %s %s?\" % (\n",
    "            header[self.column], condition, str(self.value))\n",
    "\n",
    "\n",
    "\n",
    "class Decision_Node:\n",
    "    def __init__(self,question,true_branch,false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "Column_header = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "          'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "          'pH', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "def run_decision_tree():\n",
    "\n",
    "    # Load data set\n",
    "    with open(\"wine-dataset.csv\") as f:\n",
    "        next(f, None)\n",
    "        data = [tuple(line) for line in csv.reader(f, delimiter=\",\")]\n",
    "    print (\"Number of records: %d\" % len(data))\n",
    "\n",
    "    # Split training/test sets\n",
    "    K = 11\n",
    "    training_set = [x for i, x in enumerate(data) if i % K != 10]\n",
    "    test_set = [x for i, x in enumerate(data) if i % K == 10]\n",
    "    \n",
    "    tree = DecisionTree()\n",
    "\n",
    "    # Construct a tree using training set\n",
    "    tree.learn( training_set )\n",
    "    \n",
    "    # Classify the test set using the tree we just constructed\n",
    "    results = []\n",
    "    real_ans=[]\n",
    "\n",
    "    for instance in test_set:\n",
    "        result = tree.classify( instance[:-1] )\n",
    "        results.append(result)\n",
    "        real_ans.append(float(instance[-1]))\n",
    "\n",
    "    total=len(results)\n",
    "    result_count=0\n",
    "    for i in range(len(results)):\n",
    "        if(results[i]==real_ans[i]):\n",
    "            result_count+=1\n",
    "    accuracy=float(result_count*100)/float(total)\n",
    "    \n",
    "    print( \"accuracy: %.4f\" % accuracy)       \n",
    "    \n",
    "\n",
    "    # Writing results to a file (DO NOT CHANGE)\n",
    "    f = open(myname +\"result.txt\", \"w\")\n",
    "    f.write(\"accuracy: %.4f\" % accuracy)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f739faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 4898\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 85.5102\n",
      "\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 85.7143\n",
      "\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 83.4694\n",
      "\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 85.1020\n",
      "\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 86.5306\n",
      "\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 82.8571\n",
      "\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 82.6531\n",
      "\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 83.2653\n",
      "\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 84.6626\n",
      "\n",
      "Decision tree implementing...\n",
      "Working on decisionTree, please wait for execution...\n",
      "accuracy: 83.4356\n",
      "\n",
      "Average cross validation accuracy: 84.3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3.b - Validating Accuracy using k=10 fold cross Validation \n",
    "def run_decision_tree():\n",
    "\n",
    "    # Load data set\n",
    "    with open(\"wine-dataset.csv\") as f:\n",
    "        next(f, None)\n",
    "        data = [tuple(line) for line in csv.reader(f, delimiter=\",\")]\n",
    "    print (\"Number of records: %d\" % len(data))\n",
    "\n",
    "\n",
    "    f = open(myname+\"result.txt\", \"a\")\n",
    "    # Split training/test sets\n",
    "    average = 0\n",
    "    for J in range(10):\n",
    "        K = 10\n",
    "        training_set = [x for i, x in enumerate(data) if i % K != J]\n",
    "        test_set = [x for i, x in enumerate(data) if i % K == J]\n",
    "\n",
    "        tree = DecisionTree()\n",
    "        # Construct a tree using training set\n",
    "        tree.learn(training_set)\n",
    "\n",
    "        # Classify the test set using the tree we just constructed\n",
    "        results = []\n",
    "        real_ans = []\n",
    "\n",
    "        for instance in test_set:\n",
    "            result = tree.classify(instance[:-1])\n",
    "            results.append(result)\n",
    "            real_ans.append(float(instance[-1]))\n",
    "\n",
    "        total = len(results)\n",
    "        correct_count = 0\n",
    "        for i in range(len(results)):\n",
    "            if(results[i] == real_ans[i]):\n",
    "                correct_count += 1\n",
    "\n",
    "        # Accuracy\n",
    "        accuracy = float(correct_count*100)/float(total)\n",
    "        print(\"accuracy: %.4f\\n\" % accuracy)\n",
    "        average += accuracy\n",
    "        # Writing results to a file (DO NOT CHANGE)\n",
    "        f.write(\"accuracy: %.4f\\n\" % accuracy)\n",
    "\n",
    "    average = average/10\n",
    "    f.write(\"Average cross validation accuracy: %.4f\\n\" % average)\n",
    "    print(\"Average cross validation accuracy: %.4f\\n\" % average)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfd1450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 4898\n",
      "Decision tree implementing...\n",
      "Results Using Gini Index:\n",
      "accuracy: 85.6851\n"
     ]
    }
   ],
   "source": [
    "# Q3.c - 1. Using Gini Index for improving decision tree accuracy\n",
    "def gini(rows):\n",
    "    count = class_count(rows)\n",
    "    impurity = 1\n",
    "    for lbl in count:\n",
    "        prob_of_lbl = count[lbl] / float(len(rows))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity\n",
    "\n",
    "def information_gain(left, right, present_impurity):\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return present_impurity - p * gini(left) - (1 - p) * gini(right)\n",
    "\n",
    "# Implement your decision tree Using gini index\n",
    "class DecisionTree():\n",
    "    tree = {}\n",
    "\n",
    "    def learn(self, training_set):\n",
    "       \n",
    "        training_data=[]\n",
    "        for y in training_set:\n",
    "            row=[]\n",
    "            for x in y: \n",
    "                row.append(float(x))\n",
    "            training_data.append(row)\n",
    "\n",
    "        print(\"Decision tree implementing...\")\n",
    "        print(\"Results Using Gini Index:\")\n",
    "        my_tree = build_tree(training_data)\n",
    "        self.tree[\"decision_tree\"]=my_tree\n",
    "\n",
    "    def classify(self, test_instance):\n",
    "        row=[]\n",
    "       \n",
    "        for x in test_instance:\n",
    "            row.append(float(x))\n",
    "        row.append(17)\n",
    "        result = list(classify(row, self.tree[\"decision_tree\"]).keys())[0]\n",
    "        return result\n",
    "\n",
    "def run_decision_tree():\n",
    "\n",
    "    # Load data set\n",
    "    with open(\"wine-dataset.csv\") as f:\n",
    "        next(f, None)\n",
    "        data = [tuple(line) for line in csv.reader(f, delimiter=\",\")]\n",
    "    print (\"Number of records: %d\" % len(data))\n",
    "\n",
    "    # Split training/test sets\n",
    "    K = 10\n",
    "    training_set = [x for i, x in enumerate(data) if i % K != 9]\n",
    "    test_set = [x for i, x in enumerate(data) if i % K == 9]\n",
    "    \n",
    "    tree = DecisionTree()\n",
    "\n",
    "    # Construct a tree using training set\n",
    "    tree.learn( training_set )\n",
    "\n",
    "    # Classify the test set using the tree we just constructed\n",
    "    results = []\n",
    "    real_ans=[]\n",
    "    for instance in test_set:\n",
    "        result = tree.classify( instance[:-1] )\n",
    "        results.append(result)\n",
    "        real_ans.append(float(instance[-1]))\n",
    "\n",
    "    total=len(results)\n",
    "    result_count=0\n",
    "    for i in range(len(results)):\n",
    "        if(results[i]==real_ans[i]):\n",
    "            result_count+=1\n",
    "            \n",
    "    accuracy=float(result_count*100)/float(total) \n",
    "    print( \"accuracy: %.4f\" % accuracy)       \n",
    "    \n",
    "    # Writing results to a file (DO NOT CHANGE)\n",
    "    f = open(myname+\"result.txt\", \"w\")\n",
    "    f.write(\"accuracy: %.4f\" % accuracy)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98fb4220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 4898\n",
      "Decision tree implementing...\n",
      "Results after splitting and modifying k valve:\n",
      "accuracy: 87.5000\n"
     ]
    }
   ],
   "source": [
    "# Q3.c - 2. Using Multiway split for improving decision tree accuracy\n",
    "def find_best_multiway_split(rows):\n",
    "    best_gain = 0  \n",
    "    best_question = None  \n",
    "    current_uncertainty = gini(rows)\n",
    "    n_features = len(rows[0]) - 1  \n",
    "\n",
    "    for cols in range(n_features):  \n",
    "        values = set([row[cols] for row in rows])  \n",
    "        for val in values:  \n",
    "            question = Question(cols, val)\n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "            \n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            gain = information_gain(true_rows, false_rows, current_uncertainty)\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "\n",
    "    return best_gain, best_question\n",
    "\n",
    "\n",
    "def build_tree(rows):\n",
    "    gain, question = find_best_multiway_split(rows)\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "    \n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "    true_branch = build_tree(true_rows)\n",
    "    false_branch = build_tree(false_rows)\n",
    "    return Decision_Node(question, true_branch, false_branch)\n",
    "\n",
    "\n",
    "\n",
    "# Implement decision tree \n",
    "class DecisionTree():\n",
    "    tree = {}\n",
    "\n",
    "    def learn(self, training_set):\n",
    "       \n",
    "        training_data=[]\n",
    "        for y in training_set:\n",
    "            row=[]\n",
    "            for x in y: \n",
    "                row.append(float(x))\n",
    "            training_data.append(row)\n",
    "\n",
    "        print(\"Decision tree implementing...\")\n",
    "        print(\"Results after splitting and modifying k valve:\")\n",
    "        my_tree = build_tree(training_data)\n",
    "        self.tree[\"decision_tree\"]=my_tree\n",
    "        \n",
    "\n",
    "    def classify(self, test_instance):\n",
    "        row=[]\n",
    "       \n",
    "        for x in test_instance:\n",
    "            row.append(float(x))\n",
    "        row.append(17)\n",
    "        result = list(classify(row, self.tree[\"decision_tree\"]).keys())[0]\n",
    "        return result\n",
    "\n",
    "def run_decision_tree():\n",
    "\n",
    "    # Load data set\n",
    "    with open(\"wine-dataset.csv\") as f:\n",
    "        next(f, None)\n",
    "        data = [tuple(line) for line in csv.reader(f, delimiter=\",\")]\n",
    "    print (\"Number of records: %d\" % len(data))\n",
    "\n",
    "    # Split training/test sets\n",
    "    K = 13\n",
    "    training_set = [x for i, x in enumerate(data) if i % K != 12]\n",
    "    test_set = [x for i, x in enumerate(data) if i % K == 12]\n",
    "    \n",
    "    tree = DecisionTree()\n",
    "\n",
    "    # Construct a tree using training set\n",
    "    tree.learn( training_set )\n",
    "\n",
    "    # Classify the test set using the tree we just constructed\n",
    "    results = []\n",
    "    real_ans=[]\n",
    "    for instance in test_set:\n",
    "        result = tree.classify( instance[:-1] )\n",
    "        results.append(result)\n",
    "        real_ans.append(float(instance[-1]))\n",
    "\n",
    "    total=len(results)\n",
    "    result_count=0\n",
    "    for i in range(len(results)):\n",
    "        if(results[i]==real_ans[i]):\n",
    "            result_count+=1\n",
    "            \n",
    "    accuracy=float(result_count*100)/float(total) \n",
    "    print( \"accuracy: %.4f\" % accuracy)       \n",
    "    \n",
    "    # Writing results to a file (DO NOT CHANGE)\n",
    "    f = open(myname+\"result.txt\", \"w\")\n",
    "    f.write(\"accuracy: %.4f\" % accuracy)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_decision_tree()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d20dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
